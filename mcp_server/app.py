"""MCP server exposing Temporal workflows as tools."""

from __future__ import annotations

import asyncio
import os
import secrets
from typing import Any, Dict, List
from datetime import datetime, timezone
import json
from pathlib import Path
from uuid import uuid4
from functools import partial

from mcp.server.fastmcp import FastMCP
import logging
from temporalio.client import Client, RPCError, RPCStatusCode, WorkflowExecutionStatus
from starlette.responses import JSONResponse, Response, PlainTextResponse
from starlette.requests import Request

# Import workflow classes
from tools.market_data import SubscribeCEXStream, HistoricalDataLoaderWorkflow
from tools.strategy_signal import EvaluateStrategyMomentum
from tools.execution import PlaceMockOrder, PlaceMockBatchOrder, OrderIntent, BatchOrderIntent
from tools.metrics_service import (
    MetricsRequest,
    load_dataframe_async,
    fetch_and_cache_async,
    compute_metrics_async,
    cache_file_for,
    ensure_required_columns,
    load_cached_dataframe,
)
from agents.workflows import (
    ExecutionLedgerWorkflow,
    BrokerAgentWorkflow,
    JudgeAgentWorkflow,
    StrategySpecWorkflow,
)
from tools.agent_logger import AgentLogger
from metrics import list_metrics as registry_list_metrics
from agents.event_emitter import emit_event, set_event_store
from ops_api.event_store import EventStore

LOG_LEVEL = os.environ.get("LOG_LEVEL", "INFO")
logging.basicConfig(level=LOG_LEVEL, format="[%(asctime)s] %(levelname)s: %(message)s")
logger = logging.getLogger(__name__)

# Initialize market tick logger for data continuity monitoring
market_tick_logger = AgentLogger("market_data")

# Track tick statistics for continuity monitoring
tick_stats = {
    "symbols": {},  # symbol -> {count, last_timestamp, first_timestamp}
    "total_ticks": 0,
    "session_start": int(datetime.now(timezone.utc).timestamp())
}

# Add parent directory to path for imports
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from agents.temporal_utils import get_temporal_client
from agents.strategy_planner import plan_strategy_spec
from agents.runtime_mode import get_runtime_mode

# Initialize FastMCP
app = FastMCP("crypto-trading-server")


def configure_event_store(store: EventStore) -> None:
    """Share a single EventStore across endpoints and emitters."""
    global event_store, _append_event
    event_store = store
    set_event_store(store)
    _append_event = partial(emit_event, store=event_store)


configure_event_store(EventStore())



@app.custom_route("/status", methods=["GET"])
async def status(request: Request) -> Response:
    """Expose runtime mode/latch state for Ops/UI."""
    runtime = get_runtime_mode()
    payload = {
        "stack": runtime.stack,
        "mode": runtime.mode,
        "live_trading_ack": runtime.live_trading_ack,
        "ui_unlock": runtime.ui_unlock,
        "banner": runtime.banner,
    }
    return JSONResponse(payload)


async def ensure_strategy_spec_handle(client: Client):
    """Ensure the strategy spec workflow exists and return its handle."""
    wf_id = "strategy-spec-store"
    handle = client.get_workflow_handle(wf_id)
    try:
        await handle.describe()
    except RPCError as err:
        if err.status == RPCStatusCode.NOT_FOUND:
            await client.start_workflow(
                StrategySpecWorkflow.run,
                id=wf_id,
                task_queue="mcp-tools",
            )
            handle = client.get_workflow_handle(wf_id)
        else:
            raise
    return handle


@app.tool(annotations={"title": "Subscribe CEX Stream", "readOnlyHint": True})
async def subscribe_cex_stream(
    symbols: List[str], interval_sec: int = 1
) -> Dict[str, str]:
    """Start a durable workflow to stream market data from a CEX.

    Parameters
    ----------
    symbols:
        List of asset pairs in ``BASE/QUOTE`` format.
    interval_sec:
        Number of seconds between ticker fetches.

    Returns
    -------
    Dict[str, str]
        ``workflow_id`` and ``run_id`` of the started workflow.
    """
    client = await get_temporal_client()
    workflow_id = f"stream-{secrets.token_hex(4)}"
    logger.info(
        "Starting SubscribeCEXStream: coinbase %s interval=%s",
        symbols,
        interval_sec,
    )
    logger.debug("Launching workflow %s", workflow_id)
    try:
        handle = await client.start_workflow(
            SubscribeCEXStream.run,
            args=[symbols, interval_sec],
            id=workflow_id,
            task_queue="mcp-tools",
        )
    except Exception:
        logger.exception("Failed to start SubscribeCEXStream workflow %s", workflow_id)
        raise
    logger.debug("Workflow handle created: %s", handle)
    run_id = handle.first_execution_run_id or handle.result_run_id
    logger.info("Workflow %s started run %s", workflow_id, run_id)
    return {"workflow_id": workflow_id, "run_id": run_id}


@app.tool(annotations={"title": "Start Market Stream", "readOnlyHint": True})
async def start_market_stream(
    symbols: List[str], interval_sec: int = 1, load_historical: bool = True
) -> Dict[str, str]:
    """Convenience wrapper around ``subscribe_cex_stream``.

    Also records the selected symbols for the execution agent and optionally loads historical data.

    Parameters
    ----------
    symbols:
        Trading pairs to stream.
    interval_sec:
        Seconds between ticker fetches.
    load_historical:
        Whether to load 24 hours of historical data on startup.

    Returns
    -------
    Dict[str, str]
        ``workflow_id`` and ``run_id`` of the started workflow.
    """
    # Start the real-time stream first
    result = await subscribe_cex_stream(symbols, interval_sec)
    client = await get_temporal_client()
    wf_id = os.environ.get("BROKER_WF_ID", "broker-agent")
    try:
        handle = client.get_workflow_handle(wf_id)
        await handle.signal("set_symbols", symbols)
    except RPCError as err:
        if err.status == RPCStatusCode.NOT_FOUND:
            handle = await client.start_workflow(
                BrokerAgentWorkflow.run,
                id=wf_id,
                task_queue="mcp-tools",
            )
            await handle.signal("set_symbols", symbols)
        else:
            raise
    
    # Load historical data if requested
    if load_historical:
        logger.info("Loading historical data for %d symbols", len(symbols))
        
        # Create a temporary workflow to handle historical data loading
        hist_wf_id = f"historical-loader-{secrets.token_hex(4)}"
        
        # Start a workflow that will handle the historical data loading
        await client.start_workflow(
            HistoricalDataLoaderWorkflow.run,
            args=[symbols],
            id=hist_wf_id,
            task_queue="mcp-tools"
        )
        
        logger.info("Historical data loading initiated")
                
    return result


@app.tool(annotations={"title": "Set User Preferences", "readOnlyHint": False})
async def set_user_preferences(preferences: Dict[str, Any]) -> Dict[str, str]:
    """Set user trading preferences including risk tolerance.

    Parameters
    ----------
    preferences:
        Dictionary of user preferences. Required keys:
        - experience_level: 'beginner', 'intermediate', or 'advanced'
        - risk_tolerance: 'low', 'medium', or 'high'  
        - trading_style: 'conservative', 'balanced', or 'aggressive'
        Example: {"experience_level": "intermediate", "risk_tolerance": "high", "trading_style": "aggressive"}

    Returns
    -------
    Dict[str, str]
        Confirmation of preferences set.
    """
    # Validate preferences
    if not preferences or not isinstance(preferences, dict):
        return {
            "status": "error",
            "message": "Preferences parameter is required and must be a non-empty dictionary"
        }


    required_keys = ["experience_level", "risk_tolerance", "trading_style"]
    missing_keys = [key for key in required_keys if key not in preferences]
    if missing_keys:
        return {
            "status": "error", 
            "message": f"Missing required preference keys: {missing_keys}. Required: {required_keys}"
        }
    
    client = await get_temporal_client()
    wf_id = os.environ.get("BROKER_WF_ID", "broker-agent")
    logger.info("Setting user preferences: %s", preferences)
    
    try:
        handle = client.get_workflow_handle(wf_id)
        await handle.describe()
    except RPCError as err:
        if err.status == RPCStatusCode.NOT_FOUND:
            handle = await client.start_workflow(
                BrokerAgentWorkflow.run,
                id=wf_id,
                task_queue="mcp-tools",
            )
        else:
            raise
    
    await handle.signal("set_user_preferences", preferences)
    logger.info("User preferences updated successfully")
    
    # Also signal the execution agent, judge agent, and ledger with the new preferences
    try:
        execution_handle = client.get_workflow_handle("execution-agent")
        await execution_handle.signal("set_user_preferences", preferences)
        logger.info("User preferences sent to execution agent")
    except Exception as exc:
        logger.warning("Failed to signal execution agent with preferences: %s", exc)
    
    try:
        judge_handle = client.get_workflow_handle("judge-agent")
        await judge_handle.signal("set_user_preferences", preferences)
        logger.info("User preferences sent to judge agent")
    except Exception as exc:
        logger.warning("Failed to signal judge agent with preferences: %s", exc)
    
    try:
        ledger_handle = client.get_workflow_handle(os.environ.get("LEDGER_WF_ID", "mock-ledger"))
        await ledger_handle.signal("set_user_preferences", preferences)
        logger.info("User preferences sent to ledger (including profit scraping)")
    except Exception as exc:
        logger.warning("Failed to signal ledger with preferences: %s", exc)
    
    return {
        "status": "success",
        "message": f"Updated user preferences: {', '.join(preferences.keys())}",
        "preferences_set": str(list(preferences.keys()))
    }


@app.tool(annotations={"title": "Plan Strategy", "readOnlyHint": False})
async def plan_strategy(
    market: str,
    timeframe: str,
    risk_profile: str,
    mode: str | None = None,
    notes: str | None = None,
) -> Dict[str, Any]:
    """Use the Strategy Planner to generate and persist a StrategySpec."""
    result = await plan_strategy_spec(
        market=market,
        timeframe=timeframe,
        risk_profile=risk_profile,
        mode=mode,
        notes=notes,
    )
    return {"status": "ok", "strategy": result}


@app.tool(annotations={"title": "Get Strategy Spec", "readOnlyHint": True})
async def get_strategy_spec(market: str, timeframe: str | None = None) -> Dict[str, Any]:
    """Fetch the active StrategySpec for a market/timeframe."""
    client = await get_temporal_client()
    handle = await ensure_strategy_spec_handle(client)
    spec = await handle.query("get_strategy_spec", market, timeframe)
    if not spec:
        return {
            "status": "not_found",
            "message": f"No strategy spec configured for {market}" + (f" ({timeframe})" if timeframe else ""),
        }
    return {"status": "ok", "strategy": spec}


@app.tool(annotations={"title": "List Strategy Specs", "readOnlyHint": True})
async def list_strategy_specs() -> Dict[str, Any]:
    """List all stored StrategySpec entries."""
    client = await get_temporal_client()
    handle = await ensure_strategy_spec_handle(client)
    strategies = await handle.query("list_strategy_specs")
    return {"status": "ok", "strategies": strategies}


@app.tool(annotations={"title": "Get User Preferences", "readOnlyHint": True})
async def get_user_preferences() -> Dict[str, Any]:
    """Get current user trading preferences.

    Returns
    -------
    Dict[str, Any]
        Current user preferences including risk tolerance, experience level, etc.
    """
    client = await get_temporal_client()
    wf_id = os.environ.get("BROKER_WF_ID", "broker-agent")
    logger.info("Retrieving user preferences")
    
    try:
        handle = client.get_workflow_handle(wf_id)
        await handle.describe()
    except RPCError as err:
        if err.status == RPCStatusCode.NOT_FOUND:
            handle = await client.start_workflow(
                BrokerAgentWorkflow.run,
                id=wf_id,
                task_queue="mcp-tools",
            )
        else:
            raise
    
    preferences = await handle.query("get_user_preferences")
    logger.info("Retrieved user preferences")
    
    return preferences


@app.tool(annotations={"title": "Evaluate Momentum Strategy", "readOnlyHint": True})
async def evaluate_strategy_momentum(
    signal: Dict[str, Any], cooldown_sec: int = 0
) -> Dict[str, Any]:
    """Invoke the momentum strategy evaluation workflow.

    Parameters
    ----------
    signal:
        Raw strategy signal payload.
    cooldown_sec:
        Optional delay after logging the signal.

    Returns
    -------
    Dict[str, Any]
        The logged ``signal`` payload.
    """
    client = await get_temporal_client()
    workflow_id = f"momentum-{secrets.token_hex(4)}"
    logger.info("Evaluating momentum strategy: cooldown=%s", cooldown_sec)
    handle = await client.start_workflow(
        EvaluateStrategyMomentum.run,
        args=[signal, cooldown_sec or None],
        id=workflow_id,
        task_queue="mcp-tools",
    )
    result = await handle.result()
    logger.info("Momentum workflow %s completed", workflow_id)
    return result


@app.tool(
    annotations={
        "title": "Place Mock Order",
        "readOnlyHint": False,
        "destructiveHint": False,
    }
)
async def place_mock_order(orders: List[OrderIntent]) -> Dict[str, Any]:
    """Execute trading orders with automatic portfolio updates.

    SIMPLIFIED CONSISTENT FORMAT:

    Single Order - Array with one order:
    {"orders": [{"symbol": "BTC/USD", "side": "BUY", "qty": 0.001, "price": 50000, "type": "market"}]}

    Multiple Orders - Array with multiple orders:
    {"orders": [
        {"symbol": "BTC/USD", "side": "BUY", "qty": 0.001, "price": 50000, "type": "market"},
        {"symbol": "ETH/USD", "side": "SELL", "qty": 0.1, "price": 3000, "type": "market"}
    ]}

    Validation & Execution:
    - BUY orders: Validates sufficient cash before execution
    - SELL orders: Validates sufficient holdings before execution
    - All orders: Atomic operation (all succeed or all fail)
    - Orders automatically update portfolio and trigger 20% profit scraping on profitable sells

    Parameters
    ----------
    orders:
        List of OrderIntent objects, each with {symbol, side, qty, price, type} fields

    Returns
    -------
    Dict[str, Any]
        Always returns: {order_count: int, fills: [list], total_cost: float, total_proceeds: float}
    """
    # SAFETY CHECK: Verify runtime mode before executing any orders
    runtime = get_runtime_mode()

    if runtime.is_live:
        logger.critical(
            "LIVE TRADING ORDER REQUESTED: %d orders, mode=%s, ack=%s",
            len(orders), runtime.mode, runtime.live_trading_ack
        )
        if not runtime.live_trading_ack:
            error_msg = (
                "LIVE TRADING BLOCKED: Cannot execute real trades without explicit "
                "LIVE_TRADING_ACK=true environment variable. Set LIVE_TRADING_ACK=true "
                "to acknowledge you understand this will place real orders with real money."
            )
            logger.error(error_msg)
            return {
                "error": "LIVE_TRADING_NOT_ACKNOWLEDGED",
                "message": error_msg,
                "orders_blocked": len(orders),
                "runtime_mode": runtime.mode,
                "live_trading_ack": runtime.live_trading_ack
            }
        # Log acknowledgment for audit trail
        logger.critical(
            "LIVE TRADING ACKNOWLEDGED: Proceeding with %d real orders (LIVE_TRADING_ACK=true)",
            len(orders)
        )

    client = await get_temporal_client()

    logger.info("Processing %d order(s) in %s mode", len(orders), runtime.mode)
    
    # PRE-FLIGHT VALIDATION: Check cash for all BUY orders
    total_buy_cost = 0.0
    buy_orders = []
    
    for order in orders:
        if order.side == "BUY":
            estimated_cost = float(order.qty) * float(order.price) * 1.02  # Add 2% slippage buffer
            total_buy_cost += estimated_cost
            buy_orders.append((order, estimated_cost))
    
    if buy_orders:
        try:
            ledger_wf_id = os.environ.get("LEDGER_WF_ID", "mock-ledger")
            ledger = client.get_workflow_handle(ledger_wf_id)
            
            # Check available cash
            available_cash = await ledger.query("get_cash")
            
            if available_cash < total_buy_cost:
                logger.warning(f"INSUFFICIENT CASH: Need ${total_buy_cost:.2f}, have ${available_cash:.2f}")
                return {
                    "error": "INSUFFICIENT_CASH",
                    "message": f"Cannot execute BUY orders: need ${total_buy_cost:.2f}, available ${available_cash:.2f}",
                    "required": total_buy_cost,
                    "available": available_cash,
                    "buy_order_count": len(buy_orders),
                    "total_order_count": len(orders)
                }
        except Exception as exc:
            logger.warning(f"Could not validate cash for BUY orders: {exc}")
            # Continue with orders if we can't check (fail open for now)
    
    # Create BatchOrderIntent for workflow execution
    from tools.execution import BatchOrderIntent
    batch_intent = BatchOrderIntent(orders=orders)
    
    # Execute orders via workflow
    workflow_id = f"order-{secrets.token_hex(4)}"
    logger.info("Placing order(s) via workflow %s", workflow_id)
    
    handle = await client.start_workflow(
        PlaceMockBatchOrder.run,
        batch_intent,
        id=workflow_id,
        task_queue="mcp-tools",
    )
    fills = await handle.result()
    logger.info("Order workflow %s completed with %d fills", workflow_id, len(fills))
    
    # Emit order submitted event
    await _append_event(
        "order_submitted",
        {"orders": [order.model_dump() for order in batch_intent.orders]},
        source="place_mock_batch_order",
        run_id=batch_intent.orders[0].symbol if batch_intent.orders else None,
        correlation_id=workflow_id,
    )
    
    # Record all fills in ledger
    try:
        ledger_wf_id = os.environ.get("LEDGER_WF_ID", "mock-ledger")
        ledger = client.get_workflow_handle(ledger_wf_id)
        
        # Ensure ledger workflow exists
        try:
            await ledger.describe()
        except RPCError as err:
            if err.status == RPCStatusCode.NOT_FOUND:
                ledger = await client.start_workflow(
                    ExecutionLedgerWorkflow.run,
                    id=ledger_wf_id,
                    task_queue="mcp-tools",
                )
                logger.info("Started ledger workflow %s", ledger_wf_id)
            else:
                raise
        
        # Record each fill
        for fill in fills:
            await ledger.signal("record_fill", fill)
            logger.info("Recorded fill in ledger: %s %s %s", fill["side"], fill["qty"], fill["symbol"])
            await _append_event(
                "fill",
                fill,
                source="place_mock_batch_order",
                run_id=batch_intent.orders[0].symbol if batch_intent.orders else None,
                correlation_id=fill.get("order_id"),
            )
            
    except Exception as exc:
        logger.error("Failed to record fills in ledger: %s", exc)
    
    # Prepare result
    result = {
        "order_count": len(orders),
        "fills": fills,
        "total_cost": sum(fill["cost"] for fill in fills if fill.get("side") == "BUY"),
        "total_proceeds": sum(fill["cost"] for fill in fills if fill.get("side") == "SELL")
    }
    
    return result

@app.tool(annotations={"title": "Get Historical Ticks", "readOnlyHint": True})
async def get_historical_ticks(
    symbols: List[str] | None = None,
    symbol: str | None = None,
    days: int | None = None,
    since_ts: int | None = None,
) -> Dict[str, List[Dict[str, float]]]:
    """Return historical ticks for one or more symbols.

    Parameters
    ----------
    symbols:
        List of asset pairs in ``BASE/QUOTE`` format.
    symbol:
        Single asset pair if ``symbols`` not provided (for backward compatibility).
    days:
        Number of days of history requested. ``None`` (default) returns **all**
        stored ticks.
    since_ts:
        Unix timestamp in seconds. If provided, overrides ``days`` and returns
        ticks at or after this time.
    """

    if symbols is None:
        if symbol is None:
            raise ValueError("symbol or symbols required")
        symbols = [symbol]

    if since_ts is not None:
        cutoff = since_ts
    else:
        cutoff = 0 if days is None else int(datetime.now(timezone.utc).timestamp()) - days * 86400
    client = await get_temporal_client()
    results: Dict[str, List[Dict[str, float]]] = {}
    for sym in symbols:
        wf_id = f"feature-{sym.replace('/', '-')}"
        logger.info("Querying workflow %s for ticks >= %d", wf_id, cutoff)
        handle = client.get_workflow_handle(wf_id)
        try:
            ticks_raw = await handle.query("historical_ticks", cutoff)
        except RPCError as err:
            if err.status == RPCStatusCode.NOT_FOUND:
                logger.warning("Feature workflow %s not found", wf_id)
                results[sym] = []
                continue
            raise

        ticks = [
            {"ts": int(t["ts"]), "price": float(t["price"])}
            for t in ticks_raw
        ]
        logger.info("Retrieved %d ticks for %s", len(ticks), sym)
        results[sym] = ticks

    return results


@app.tool(annotations={"title": "List Technical Metrics", "readOnlyHint": True})
async def list_technical_metrics() -> Dict[str, Any]:
    """Return the list of registered technical indicators."""

    metrics = registry_list_metrics()
    return {"metrics": metrics, "count": len(metrics)}


@app.tool(annotations={"title": "Update Market Cache", "readOnlyHint": False})
async def update_market_cache(
    symbol: str,
    timeframe: str = "1h",
    limit: int = 500,
    overwrite: bool = False,
) -> Dict[str, Any]:
    """Fetch OHLCV candles from Coinbase Exchange and cache locally."""

    cache_path = cache_file_for(symbol, timeframe, limit)
    if cache_path.exists() and not overwrite:
        df = load_cached_dataframe(cache_path)
        saved_path = cache_path
        action = "loaded"
    else:
        if overwrite and cache_path.exists():
            cache_path.unlink()
        df, saved_path = await fetch_and_cache_async(symbol, timeframe, limit, cache_path)
        action = "fetched"

    preview = df.tail(5).to_dict(orient="records")
    return {
        "status": "success",
        "symbol": symbol,
        "timeframe": timeframe,
        "limit": limit,
        "rows": len(df),
        "cache_path": str(saved_path),
        "action": action,
        "preview": preview,
    }


@app.tool(annotations={"title": "Compute Technical Metrics", "readOnlyHint": True})
async def compute_technical_metrics(
    symbol: str,
    timeframe: str = "1h",
    limit: int = 500,
    features: List[str] | None = None,
    params: Dict[str, Dict[str, Any]] | None = None,
    output: str = "wide",
    tail: int = 50,
    use_cache: bool = True,
    fetch_if_missing: bool = True,
    data_path: str | None = None,
) -> Dict[str, Any]:
    """Compute Tier I technical metrics over OHLCV data."""

    selected_features = features or registry_list_metrics()
    params = params or {}
    request = MetricsRequest(
        symbol=symbol,
        timeframe=timeframe,
        limit=limit,
        use_cache=use_cache,
        data_path=Path(data_path) if data_path else None,
    )

    df = await load_dataframe_async(request, fetch_if_missing=fetch_if_missing)
    ensure_required_columns(df)

    metrics_df = await compute_metrics_async(df, selected_features, params=params, output=output)

    tail = max(tail, 1)
    if output == "wide":
        preview_df = metrics_df.tail(tail)
    else:
        preview_df = metrics_df.tail(tail * len(selected_features))

    return {
        "symbol": symbol,
        "timeframe": timeframe,
        "limit": limit,
        "features": selected_features,
        "output": output,
        "rows": len(metrics_df),
        "preview": preview_df.to_dict(orient="records"),
        "cache_path": str(cache_file_for(symbol, timeframe, limit)),
    }


def _empty_portfolio_snapshot(reason: str) -> Dict[str, Any]:
    return {
        "cash": 0.0,
        "positions": {},
        "entry_prices": {},
        "position_details": {},
        "total_position_value": 0.0,
        "total_portfolio_value": 0.0,
        "total_pnl": 0.0,
        "pnl": 0.0,
        "realized_pnl": 0.0,
        "unrealized_pnl": 0.0,
        "scraped_profits": 0.0,
        "available_cash": 0.0,
        "total_cash_value": 0.0,
        "price_data_quality": {
            "live_prices_used": 0,
            "total_positions": 0,
            "using_stale_fallback": False,
            "price_fetch_errors": [reason],
        },
        "live_prices_used": {},
        "status": "fallback",
    }


@app.tool(annotations={"title": "Get Portfolio Status", "readOnlyHint": True})
async def get_portfolio_status() -> Dict[str, Any]:
    """Retrieve current portfolio cash and positions from the ledger."""

    def _fallback(reason: str) -> Dict[str, Any]:
        return _empty_portfolio_snapshot(reason)

    try:
        client = await get_temporal_client()
        wf_id = os.environ.get("LEDGER_WF_ID", "mock-ledger")
        logger.info("Fetching portfolio status from %s", wf_id)
        try:
            handle = client.get_workflow_handle(wf_id)
            await handle.describe()
        except RPCError as err:
            if err.status == RPCStatusCode.NOT_FOUND:
                handle = await client.start_workflow(
                    ExecutionLedgerWorkflow.run,
                    id=wf_id,
                    task_queue="mcp-tools",
                )
            else:
                raise

        cash = await handle.query("get_cash")
        positions = await handle.query("get_positions")
        entry_prices = await handle.query("get_entry_prices")
        realized_pnl = await handle.query("get_realized_pnl")
        scraped_profits = await handle.query("get_scraped_profits")

        live_prices: Dict[str, float] = {}
        price_fetch_errors: List[str] = []
        if positions:
            symbols = list(positions.keys())
            for symbol in symbols:
                wf_id = f"feature-{symbol.replace('/', '-')}"
                try:
                    feature_handle = client.get_workflow_handle(wf_id)
                    price_info = await feature_handle.query("get_latest_price")
                    if price_info["price"] is not None and price_info["age_seconds"] <= 60:
                        live_prices[symbol] = price_info["price"]
                    elif price_info["price"] is not None:
                        price_fetch_errors.append(f"{symbol}: price is {price_info['age_seconds']:.1f}s stale")
                    else:
                        price_fetch_errors.append(f"{symbol}: no price data from feature workflow")
                except Exception as exc:
                    price_fetch_errors.append(f"{symbol}: failed to query feature workflow - {exc}")
                    logger.warning("Failed to get latest price for %s: %s", symbol, exc)

        if live_prices:
            pnl = await handle.query("get_pnl_with_live_prices", live_prices)
            unrealized_pnl = await handle.query("get_unrealized_pnl_with_live_prices", live_prices)
        else:
            pnl = await handle.query("get_pnl")
            unrealized_pnl = await handle.query("get_unrealized_pnl")

        position_details: Dict[str, Dict[str, float]] = {}
        total_position_value = 0.0
        for symbol, quantity in positions.items():
            entry_price = entry_prices.get(symbol, 0.0)
            current_price = live_prices.get(symbol, entry_price)
            entry_value = quantity * entry_price
            current_value = quantity * current_price
            position_pnl = current_value - entry_value
            position_pnl_pct = (position_pnl / entry_value * 100) if entry_value else 0.0
            total_position_value += current_value
            position_details[symbol] = {
                "quantity": quantity,
                "entry_price": entry_price,
                "current_price": current_price,
                "entry_value": entry_value,
                "current_value": current_value,
                "position_pnl": position_pnl,
                "position_pnl_pct": position_pnl_pct,
                "price_is_live": symbol in live_prices,
            }

        total_portfolio_value = cash + total_position_value + scraped_profits
        return {
            "cash": cash,
            "positions": positions,
            "entry_prices": entry_prices,
            "position_details": position_details,
            "total_position_value": total_position_value,
            "total_portfolio_value": total_portfolio_value,
            "total_pnl": pnl,
            "pnl": pnl,
            "realized_pnl": realized_pnl,
            "unrealized_pnl": unrealized_pnl,
            "scraped_profits": scraped_profits,
            "available_cash": cash,
            "total_cash_value": cash + scraped_profits,
            "price_data_quality": {
                "live_prices_used": len(live_prices),
                "total_positions": len(positions),
                "using_stale_fallback": len(live_prices) < len(positions),
                "price_fetch_errors": price_fetch_errors,
            },
            "live_prices_used": live_prices,
            "status": "ok",
        }
    except Exception as exc:
        logger.warning("Portfolio status fallback triggered: %s", exc)
        return _fallback(str(exc))


@app.tool(annotations={"title": "Get Transaction History", "readOnlyHint": True})
async def get_transaction_history(
    since_ts: int = 0, limit: int = 1000
) -> Dict[str, Any]:
    """Get transaction history from the execution ledger.
    
    Parameters
    ----------
    since_ts:
        Unix timestamp in seconds. Only transactions at or after this time.
    limit:
        Maximum number of transactions to return.
        
    Returns
    -------
    Dict[str, Any]
        Transaction history with metadata.
    """
    client = await get_temporal_client()
    wf_id = os.environ.get("LEDGER_WF_ID", "mock-ledger")
    logger.info("Fetching transaction history from %s", wf_id)
    
    try:
        handle = client.get_workflow_handle(wf_id)
        await handle.describe()
    except RPCError as err:
        if err.status == RPCStatusCode.NOT_FOUND:
            handle = await client.start_workflow(
                ExecutionLedgerWorkflow.run,
                id=wf_id,
                task_queue="mcp-tools",
            )
        else:
            raise
    
    transactions = await handle.query("get_transaction_history", {"since_ts": since_ts, "limit": limit})
    logger.info("Retrieved %d transactions", len(transactions))
    
    return {
        "transactions": transactions,
        "count": len(transactions),
        "since_timestamp": since_ts,
        "limit": limit
    }


@app.tool(annotations={"title": "Get Performance Metrics", "readOnlyHint": True})
async def get_performance_metrics(window_days: int = 30) -> Dict[str, Any]:
    """Get performance metrics from the execution ledger.
    
    Parameters
    ----------
    window_days:
        Number of days to analyze for performance metrics.
        
    Returns
    -------
    Dict[str, Any]
        Performance metrics including returns, drawdown, trade statistics.
    """
    client = await get_temporal_client()
    wf_id = os.environ.get("LEDGER_WF_ID", "mock-ledger")
    logger.info("Fetching performance metrics from %s for %d days", wf_id, window_days)
    
    try:
        handle = client.get_workflow_handle(wf_id)
        await handle.describe()
    except RPCError as err:
        if err.status == RPCStatusCode.NOT_FOUND:
            handle = await client.start_workflow(
                ExecutionLedgerWorkflow.run,
                id=wf_id,
                task_queue="mcp-tools",
            )
        else:
            raise
    
    metrics = await handle.query("get_performance_metrics", window_days)
    logger.info("Retrieved performance metrics")
    
    return metrics


@app.tool(annotations={"title": "Get Risk Metrics", "readOnlyHint": True})
async def get_risk_metrics() -> Dict[str, Any]:
    """Get current risk metrics from the execution ledger.
        
    Returns
    -------
    Dict[str, Any]
        Risk metrics including position concentration, leverage, cash ratio.
    """
    client = await get_temporal_client()
    wf_id = os.environ.get("LEDGER_WF_ID", "mock-ledger")
    logger.info("Fetching risk metrics from %s", wf_id)
    
    try:
        handle = client.get_workflow_handle(wf_id)
        await handle.describe()
    except RPCError as err:
        if err.status == RPCStatusCode.NOT_FOUND:
            handle = await client.start_workflow(
                ExecutionLedgerWorkflow.run,
                id=wf_id,
                task_queue="mcp-tools",
            )
        else:
            raise
    
    # Get positions to fetch live prices  
    positions = await handle.query("get_positions")
    
    # Get live market prices for all positions using efficient get_latest_price query
    live_prices = {}
    price_fetch_status = {"success": True, "errors": [], "stale_count": 0}
    
    if positions:
        symbols = list(positions.keys())
        client = await get_temporal_client()
        
        for symbol in symbols:
            wf_id = f"feature-{symbol.replace('/', '-')}"
            try:
                feature_handle = client.get_workflow_handle(wf_id)
                price_info = await feature_handle.query("get_latest_price")
                
                if price_info["price"] is not None and price_info["age_seconds"] <= 60:
                    # Fresh price available
                    live_prices[symbol] = price_info["price"]
                elif price_info["price"] is not None:
                    # Stale price
                    price_fetch_status["stale_count"] += 1
                    price_fetch_status["errors"].append(f"{symbol}: price is {price_info['age_seconds']:.1f}s old")
                else:
                    # No price data available
                    price_fetch_status["errors"].append(f"{symbol}: no price data from feature workflow")
                    
            except Exception as e:
                price_fetch_status["success"] = False
                price_fetch_status["errors"].append(f"{symbol}: failed to query feature workflow - {str(e)}")
                logger.warning("Failed to get latest price for risk metrics %s: %s", symbol, e)
    
    # Calculate risk metrics with live prices if available
    if live_prices:
        metrics = await handle.query("get_risk_metrics_with_live_prices", live_prices)
        logger.info("Retrieved risk metrics with live prices for %d symbols", len(live_prices))
    else:
        metrics = await handle.query("get_risk_metrics")
        logger.info("Retrieved risk metrics with last fill prices")
    
    # Add price data quality information to the response
    metrics["price_data_quality"] = {
        "live_prices_used": len(live_prices),
        "total_positions": len(positions),
        "price_fetch_status": price_fetch_status,
        "using_stale_fallback": len(live_prices) < len(positions)
    }
    
    return metrics


@app.tool(annotations={"title": "Get PnL Status with Data Quality", "readOnlyHint": True})
async def get_pnl_status_with_quality() -> Dict[str, Any]:
    """Get PnL status with detailed information about price data quality.
    
    Returns
    -------
    Dict[str, Any]
        PnL information including data quality metrics and staleness warnings.
    """
    client = await get_temporal_client()
    wf_id = os.environ.get("LEDGER_WF_ID", "mock-ledger")
    
    try:
        handle = client.get_workflow_handle(wf_id)
        await handle.describe()
    except RPCError as err:
        if err.status == RPCStatusCode.NOT_FOUND:
            return {
                "error": "No trading data available - ledger workflow not started",
                "total_pnl": 0.0,
                "realized_pnl": 0.0,
                "unrealized_pnl": 0.0,
                "price_staleness_info": {"stale_symbols": [], "fresh_symbols": []}
            }
        else:
            raise
    
    # Get PnL data
    total_pnl = await handle.query("get_pnl")
    realized_pnl = await handle.query("get_realized_pnl")
    unrealized_pnl = await handle.query("get_unrealized_pnl")
    
    # Get price staleness information
    staleness_info = await handle.query("get_price_staleness_info")
    
    # Get positions to fetch live prices
    positions = await handle.query("get_positions")
    
    # Attempt to get live prices for comparison using efficient get_latest_price query
    live_prices = {}
    live_price_errors = []
    
    if positions:
        symbols = list(positions.keys())
        client = await get_temporal_client()
        
        for symbol in symbols:
            wf_id = f"feature-{symbol.replace('/', '-')}"
            try:
                feature_handle = client.get_workflow_handle(wf_id)
                price_info = await feature_handle.query("get_latest_price")
                
                if price_info["price"] is not None and price_info["age_seconds"] <= 60:
                    # Fresh price available
                    live_prices[symbol] = price_info["price"]
                elif price_info["price"] is not None:
                    # Stale price
                    live_price_errors.append(f"{symbol}: live price is {price_info['age_seconds']:.1f}s stale")
                else:
                    # No price data available
                    live_price_errors.append(f"{symbol}: no live price data from feature workflow")
                    
            except Exception as e:
                live_price_errors.append(f"{symbol}: failed to query feature workflow - {str(e)}")
                logger.warning("Failed to get latest price for PnL quality check %s: %s", symbol, e)
    
    # Calculate PnL with live prices if available
    live_pnl_data = None
    if live_prices:
        try:
            live_total_pnl = await handle.query("get_pnl_with_live_prices", live_prices)
            live_unrealized_pnl = await handle.query("get_unrealized_pnl_with_live_prices", live_prices)
            live_pnl_data = {
                "total_pnl": live_total_pnl,
                "unrealized_pnl": live_unrealized_pnl,
                "symbols_with_live_prices": list(live_prices.keys())
            }
        except Exception as e:
            live_price_errors.append(f"Live PnL calculation failed: {str(e)}")
    
    return {
        "total_pnl": total_pnl,
        "realized_pnl": realized_pnl,
        "unrealized_pnl": unrealized_pnl,
        "live_pnl_data": live_pnl_data,
        "price_staleness_info": staleness_info,
        "live_price_status": {
            "available_symbols": len(live_prices),
            "total_symbols": len(positions),
            "errors": live_price_errors
        },
        "accuracy_warning": len(staleness_info.get("stale_symbols", [])) > 0 or len(live_price_errors) > 0
    }


@app.tool(annotations={"title": "Trigger Performance Evaluation", "readOnlyHint": False})
async def trigger_performance_evaluation(
    window_days: int = 7, force: bool = False
) -> Dict[str, Any]:
    """Trigger a performance evaluation by the judge agent.
    
    Parameters
    ----------
    window_days:
        Number of days to analyze for the evaluation.
    force:
        Force evaluation even if cooldown period hasn't elapsed.
        
    Returns
    -------
    Dict[str, Any]
        Evaluation trigger result.
    """
    client = await get_temporal_client()
    judge_wf_id = os.environ.get("JUDGE_WF_ID", "judge-agent")
    logger.info("Triggering performance evaluation")
    
    try:
        handle = client.get_workflow_handle(judge_wf_id)
        await handle.describe()
    except RPCError as err:
        if err.status == RPCStatusCode.NOT_FOUND:
            handle = await client.start_workflow(
                JudgeAgentWorkflow.run,
                id=judge_wf_id,
                task_queue="mcp-tools",
            )
            logger.info("Started judge agent workflow")
        else:
            raise
    
    # Check if evaluation should be triggered
    if not force:
        should_evaluate = await handle.query("should_trigger_evaluation", 4)
        if not should_evaluate:
            return {
                "triggered": False,
                "reason": "Evaluation cooldown period has not elapsed",
                "suggestion": "Use force=true to override cooldown"
            }
    
    # Create evaluation trigger signal
    trigger_data = {
        "window_days": window_days,
        "trigger_timestamp": int(datetime.now(timezone.utc).timestamp()),
        "force": force
    }
    
    # Signal the judge agent to trigger an immediate evaluation
    await handle.signal("trigger_immediate_evaluation", {
        "window_days": window_days,
        "forced": force,
        "trigger_timestamp": trigger_data["trigger_timestamp"]
    })
    
    logger.info("Performance evaluation triggered")
    
    return {
        "triggered": True,
        "window_days": window_days,
        "forced": force,
        "message": "Performance evaluation has been requested"
    }


@app.tool(annotations={"title": "Get Judge Evaluations", "readOnlyHint": True})
async def get_judge_evaluations(limit: int = 20, since_ts: int = 0) -> Dict[str, Any]:
    """Get recent performance evaluations from the judge agent.
    
    Parameters
    ----------
    limit:
        Maximum number of evaluations to return.
    since_ts:
        Unix timestamp in seconds. Only evaluations at or after this time.
        
    Returns
    -------
    Dict[str, Any]
        Recent evaluations and performance trends.
    """
    client = await get_temporal_client()
    judge_wf_id = os.environ.get("JUDGE_WF_ID", "judge-agent")
    logger.info("Fetching judge evaluations")
    
    try:
        handle = client.get_workflow_handle(judge_wf_id)
        await handle.describe()
    except RPCError as err:
        if err.status == RPCStatusCode.NOT_FOUND:
            logger.warning("Judge workflow not found")
            return {
                "evaluations": [],
                "count": 0,
                "trend": {"trend": "unknown", "avg_score": 0.0}
            }
        else:
            raise
    
    evaluations = await handle.query("get_evaluations", {"limit": limit, "since_ts": since_ts})
    trend = await handle.query("get_performance_trend", 30)
    
    logger.info("Retrieved %d evaluations", len(evaluations))
    
    return {
        "evaluations": evaluations,
        "count": len(evaluations),
        "trend": trend
    }


@app.tool(annotations={"title": "Send User Feedback", "readOnlyHint": False})
async def send_user_feedback(
    target_agent: str, 
    message: str
) -> Dict[str, Any]:
    """Send feedback to either the execution or judge agent.
    
    This allows users to provide contextual feedback that will be incorporated
    into the agent's conversation loop or evaluation process.
    
    Parameters
    ----------
    target_agent:
        Which agent to send feedback to: "execution" or "judge"
    message:
        The feedback message to send
        
    Returns
    -------
    Dict[str, Any]
        Status of the feedback delivery
    """
    client = await get_temporal_client()
    
    try:
        feedback_data = {
            "message": message,
            "source": "user",
            "timestamp": int(datetime.now(timezone.utc).timestamp())
        }
        
        if target_agent.lower() == "execution":
            handle = client.get_workflow_handle("execution-agent")
            await handle.signal("add_user_feedback", feedback_data)
            logger.info(f"User feedback sent to execution agent: {message[:100]}...")
            return {
                "success": True,
                "target": "execution-agent",
                "message": "Feedback sent to execution agent successfully",
                "feedback_preview": message[:200] + "..." if len(message) > 200 else message
            }
            
        elif target_agent.lower() == "judge":
            handle = client.get_workflow_handle("judge-agent")
            await handle.signal("add_user_feedback", feedback_data)
            logger.info(f"User feedback sent to judge agent: {message[:100]}...")
            return {
                "success": True,
                "target": "judge-agent",
                "message": "Feedback sent to judge agent successfully",
                "feedback_preview": message[:200] + "..." if len(message) > 200 else message
            }
            
        else:
            return {
                "success": False,
                "error": f"Invalid target agent: {target_agent}. Must be 'execution' or 'judge'"
            }
            
    except Exception as exc:
        logger.error(f"Failed to send user feedback: {exc}")
        return {
            "success": False,
            "error": f"Failed to send feedback: {str(exc)}"
        }


@app.tool(annotations={"title": "Get Pending Feedback", "readOnlyHint": True})
async def get_pending_feedback(target_agent: str) -> Dict[str, Any]:
    """Get any pending (unprocessed) feedback for an agent.
    
    Parameters
    ----------
    target_agent:
        Which agent to check: "execution" or "judge"
        
    Returns
    -------
    Dict[str, Any]
        List of pending feedback messages
    """
    client = await get_temporal_client()
    
    try:
        if target_agent.lower() == "execution":
            handle = client.get_workflow_handle("execution-agent")
            pending = await handle.query("get_pending_feedback")
            return {
                "success": True,
                "target": "execution-agent",
                "pending_feedback": pending,
                "count": len(pending)
            }
            
        elif target_agent.lower() == "judge":
            handle = client.get_workflow_handle("judge-agent")
            pending = await handle.query("get_pending_feedback")
            return {
                "success": True,
                "target": "judge-agent",
                "pending_feedback": pending,
                "count": len(pending)
            }
            
        else:
            return {
                "success": False,
                "error": f"Invalid target agent: {target_agent}. Must be 'execution' or 'judge'"
            }
            
    except Exception as exc:
        logger.error(f"Failed to get pending feedback: {exc}")
        return {
            "success": False,
            "error": f"Failed to retrieve feedback: {str(exc)}"
        }


@app.tool(annotations={"title": "Get Prompt History", "readOnlyHint": True})
async def get_prompt_history(limit: int = 10) -> Dict[str, Any]:
    """Get prompt version history from the judge agent.
    
    Parameters
    ----------
    limit:
        Maximum number of prompt versions to return.
        
    Returns
    -------
    Dict[str, Any]
        Prompt version history and current active version.
    """
    client = await get_temporal_client()
    judge_wf_id = os.environ.get("JUDGE_WF_ID", "judge-agent")
    logger.info("Fetching prompt history")
    
    try:
        handle = client.get_workflow_handle(judge_wf_id)
        await handle.describe()
    except RPCError as err:
        if err.status == RPCStatusCode.NOT_FOUND:
            logger.warning("Judge workflow not found")
            return {
                "versions": [],
                "current_version": {},
                "count": 0
            }
        else:
            raise
    
    versions = await handle.query("get_prompt_versions", limit)
    current_version = await handle.query("get_current_prompt_version")
    
    logger.info("Retrieved %d prompt versions", len(versions))
    
    return {
        "versions": versions,
        "current_version": current_version,
        "count": len(versions)
    }


@app.custom_route("/workflow/{workflow_id}/{run_id}", methods=["GET"])
async def workflow_status(request: Request) -> Response:
    workflow_id = request.path_params["workflow_id"]
    run_id = request.path_params["run_id"]
    logger.info("Fetching status for %s %s", workflow_id, run_id)
    client = await get_temporal_client()
    handle = client.get_workflow_handle(workflow_id, run_id=run_id)
    desc = await handle.describe()
    status_name = desc.status.name if desc.status else "UNKNOWN"
    result: Any | None = None
    if desc.status and desc.status != WorkflowExecutionStatus.RUNNING:
        try:
            result = await handle.result()
        except Exception as exc:
            result = {"error": str(exc)}
    logger.info("Workflow %s status %s", workflow_id, status_name)
    return JSONResponse({"status": status_name, "result": result})


def _log_tick_continuity_summary() -> None:
    """Log a summary of tick data continuity for monitoring."""
    try:
        current_time = int(datetime.now(timezone.utc).timestamp())
        session_duration = current_time - tick_stats["session_start"]
        
        # Calculate continuity metrics per symbol
        symbol_continuity = {}
        for symbol, stats in tick_stats["symbols"].items():
            data_span = stats["last_timestamp"] - stats["first_timestamp"]
            expected_ticks = max(1, data_span)  # Assume ~1 tick per second
            continuity_ratio = stats["count"] / expected_ticks if expected_ticks > 0 else 1.0
            
            symbol_continuity[symbol] = {
                "tick_count": stats["count"],
                "data_span_seconds": data_span,
                "continuity_ratio": min(1.0, continuity_ratio),
                "first_tick": stats["first_timestamp"],
                "latest_tick": stats["last_timestamp"],
                "gap_from_now": current_time - stats["last_timestamp"]
            }
        
        market_tick_logger.log_summary(
            summary_type="tick_continuity_report",
            data={
                "session_duration_seconds": session_duration,
                "total_ticks_received": tick_stats["total_ticks"],
                "symbols_tracked": len(tick_stats["symbols"]),
                "symbols_continuity": symbol_continuity,
                "overall_tick_rate": tick_stats["total_ticks"] / session_duration if session_duration > 0 else 0,
                "potential_gaps": [
                    symbol for symbol, stats in symbol_continuity.items() 
                    if stats["gap_from_now"] > 30  # More than 30 seconds since last tick
                ]
            }
        )
        
    except Exception as e:
        logger.error(f"Failed to log tick continuity summary: {e}")


@app.custom_route("/signal/{name}", methods=["POST"])
async def record_signal(request: Request) -> Response:
    """Record a signal event (durable via event store)."""
    name = request.path_params["name"]
    payload = await request.json()
    ts = payload.get("ts")
    if ts is None:
        ts = int(datetime.now(timezone.utc).timestamp())
        payload["ts"] = ts

    event_type = "intent"
    if name == "market_tick":
        event_type = "tick"
    elif name == "approved_intent":
        event_type = "intent"
    elif name == "order_submitted":
        event_type = "order_submitted"
    elif name == "position_update":
        event_type = "position_update"

    await _append_event(
        event_type,
        payload,
        source=name,
        run_id=payload.get("run_id"),
        correlation_id=payload.get("correlation_id"),
        dedupe_key=payload.get("dedupe_key"),
    )

    # Log market tick data for continuity monitoring
    if name == "market_tick":
        try:
            symbol = payload.get("symbol")
            tick_timestamp = payload.get("timestamp", ts)

            # Update tick statistics
            tick_stats["total_ticks"] += 1
            if symbol:
                if symbol not in tick_stats["symbols"]:
                    tick_stats["symbols"][symbol] = {
                        "count": 0,
                        "first_timestamp": tick_timestamp,
                        "last_timestamp": tick_timestamp
                    }

                symbol_stats = tick_stats["symbols"][symbol]
                symbol_stats["count"] += 1
                symbol_stats["last_timestamp"] = max(symbol_stats["last_timestamp"], tick_timestamp)
                symbol_stats["first_timestamp"] = min(symbol_stats["first_timestamp"], tick_timestamp)

            market_tick_logger.log_action(
                action_type="market_tick_received",
                details={
                    "symbol": symbol,
                    "price": payload.get("price"),
                    "timestamp": tick_timestamp,
                    "volume": payload.get("volume"),
                    "high": payload.get("high"),
                    "low": payload.get("low"),
                    "open": payload.get("open"),
                    "close": payload.get("close")
                },
                result={"recorded": True},
                signal_name=name,
                payload_timestamp=ts
            )

            if tick_stats["total_ticks"] % 100 == 0:
                _log_tick_continuity_summary()

        except Exception as log_error:
            logger.error(f"Failed to log market tick: {log_error}")

    logger.debug("Recorded signal %s", name)
    return Response(status_code=204)


@app.custom_route("/signal/{name}", methods=["GET"])
async def fetch_signals(request: Request) -> Response:
    """Return signal events newer than the provided ``after`` timestamp."""

    name = request.path_params["name"]
    after = int(request.query_params.get("after", "0"))
    after_dt = datetime.fromtimestamp(after, tz=timezone.utc)

    events = await asyncio.to_thread(event_store.list_events, 500)
    filtered = [
        json.loads(evt.model_dump_json())
        for evt in events
        if evt.source == name and evt.ts.replace(tzinfo=timezone.utc) > after_dt
    ]
    return JSONResponse(filtered)


@app.custom_route("/healthz", methods=["GET"])
async def healthz(_request):
    return PlainTextResponse("ok", status_code=200)


# ---- Simple HTTP shims to invoke selected MCP tools ----
@app.custom_route("/tools/start_market_stream", methods=["POST"])
async def http_start_market_stream(request: Request) -> Response:
    body = await request.json()
    symbols = body.get("symbols") or []
    interval_sec = int(body.get("interval_sec", 1))
    load_historical = bool(body.get("load_historical", True))
    result = await start_market_stream(symbols, interval_sec, load_historical)
    return JSONResponse(result)


@app.custom_route("/tools/subscribe_cex_stream", methods=["POST"])
async def http_subscribe_cex_stream(request: Request) -> Response:
    body = await request.json()
    symbols = body.get("symbols") or []
    interval_sec = int(body.get("interval_sec", 1))
    result = await subscribe_cex_stream(symbols, interval_sec)
    return JSONResponse(result)

@app.custom_route("/tools/get_portfolio_status", methods=["GET", "POST"])
async def http_get_portfolio_status(_request: Request) -> Response:
    result = await get_portfolio_status()
    return JSONResponse(result)

@app.custom_route("/tools/place_mock_order", methods=["POST"])
async def http_place_mock_order(request: Request) -> Response:
    body = await request.json()
    orders = body.get("orders") or []
    # let pydantic/dataclass conversion inside tool handle types
    result = await place_mock_order(orders)
    return JSONResponse(result)

@app.custom_route("/tools/get_transaction_history", methods=["GET"])
async def http_get_tx(_request: Request) -> Response:
    result = await get_transaction_history()
    return JSONResponse(result)

@app.custom_route("/tools/trigger_evaluation", methods=["POST"])
async def http_trigger_eval(request: Request) -> Response:
    body = await request.json()
    window_days = int(body.get("window_days", 7))
    force = bool(body.get("force", False))
    result = await trigger_performance_evaluation(window_days, force)
    return JSONResponse(result)



if __name__ == "__main__":
    app.settings.host = "0.0.0.0"
    app.settings.port = int(os.environ.get("MCP_PORT", "8080"))
    logger.info("Starting MCP server on %s:%s", app.settings.host, app.settings.port)
    app.run(transport="streamable-http")
